#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å‡ºé¦¬è¡¨ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆãƒ‡ãƒãƒƒã‚°ç‰ˆ v2.2ï¼‰
- HTMLæ§‹é€ ã®è©³ç´°ãƒ­ã‚°ã‚’è¿½åŠ 
"""

import json
import re
import time
import sys
from datetime import datetime
import requests
from bs4 import BeautifulSoup

def fetch_race_data(race_id):
    """
    æŒ‡å®šã•ã‚ŒãŸrace_idã®å‡ºé¦¬è¡¨ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ä»˜ãï¼‰
    """
    url = f"https://nar.netkeiba.com/race/shutuba.html?race_id={race_id}"
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
    
    try:
        print(f"\nğŸ” [DEBUG] URL: {url}")
        resp = requests.get(url, headers=headers, timeout=10)
        resp.encoding = 'EUC-JP'
        
        print(f"ğŸ” [DEBUG] HTTP Status: {resp.status_code}")
        print(f"ğŸ” [DEBUG] Response Length: {len(resp.text)} characters")
        
        if resp.status_code != 200:
            print(f"âŒ HTTP Error {resp.status_code} for race_id={race_id}")
            return None
        
        soup = BeautifulSoup(resp.text, 'html.parser')
        
        # ãƒ‡ãƒãƒƒã‚°: ãƒ†ãƒ¼ãƒ–ãƒ«ã®å­˜åœ¨ç¢ºèª
        horse_table = soup.find('table', class_='Shutuba_Table')
        print(f"ğŸ” [DEBUG] Shutuba_Table found: {horse_table is not None}")
        
        if not horse_table:
            # ã™ã¹ã¦ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ¤œç´¢
            all_tables = soup.find_all('table')
            print(f"ğŸ” [DEBUG] Total tables found: {len(all_tables)}")
            for idx, table in enumerate(all_tables[:3]):  # æœ€åˆã®3ã¤ã ã‘
                table_classes = table.get('class', [])
                print(f"ğŸ” [DEBUG] Table {idx+1} classes: {table_classes}")
        
        # ãƒ¬ãƒ¼ã‚¹åŸºæœ¬æƒ…å ±ã®å–å¾—
        race_info = extract_race_info(soup, race_id)
        if not race_info:
            print(f"âš ï¸ ãƒ¬ãƒ¼ã‚¹æƒ…å ±ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ: {race_id}")
            return None
        
        # é¦¬ãƒ‡ãƒ¼ã‚¿ã®å–å¾—
        horses = extract_horses(soup)
        if not horses:
            print(f"âš ï¸ é¦¬ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ: {race_id}")
            print(f"ğŸ” [DEBUG] Checking HTML structure...")
            
            # ãƒ‡ãƒãƒƒã‚°: é¦¬åã‚’å«ã‚€è¦ç´ ã‚’æ¤œç´¢
            horse_names = soup.find_all('a', href=re.compile(r'/horse/'))
            print(f"ğŸ” [DEBUG] Horse links found: {len(horse_names)}")
            if horse_names:
                print(f"ğŸ” [DEBUG] First horse: {horse_names[0].get_text(strip=True)}")
            
            return None
        
        race_info['horses'] = horses
        race_info['å–å¾—é ­æ•°'] = len(horses)
        
        print(f"âœ… {race_info.get('ãƒ¬ãƒ¼ã‚¹å', 'N/A')}: {len(horses)}é ­")
        
        return race_info
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {race_id} - {str(e)}")
        import traceback
        traceback.print_exc()
        return None


def extract_race_info(soup, race_id):
    """
    ãƒ¬ãƒ¼ã‚¹åŸºæœ¬æƒ…å ±ã‚’æŠ½å‡º
    """
    race_data = {
        'race_id': race_id
    }
    
    # ãƒ¬ãƒ¼ã‚¹å
    race_title = soup.find('div', class_='RaceName')
    if race_title:
        race_data['ãƒ¬ãƒ¼ã‚¹å'] = race_title.get_text(strip=True)
        print(f"ğŸ” [DEBUG] Race name: {race_data['ãƒ¬ãƒ¼ã‚¹å']}")
    else:
        print(f"ğŸ” [DEBUG] RaceName div not found")
    
    # ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ï¼ˆè·é›¢ã€ç™ºèµ°æ™‚åˆ»ãªã©ï¼‰
    race_data_div = soup.find('div', class_='RaceData01')
    if race_data_div:
        race_text = race_data_div.get_text(strip=True)
        
        # è·é›¢ã®æŠ½å‡º
        distance_match = re.search(r'([ãƒ€èŠ])(\d+)m', race_text)
        if distance_match:
            race_data['ãƒˆãƒ©ãƒƒã‚¯'] = distance_match.group(1)
            race_data['è·é›¢'] = int(distance_match.group(2))
        
        # ç™ºèµ°æ™‚åˆ»
        time_match = re.search(r'(\d{1,2}):(\d{2})ç™ºèµ°', race_text)
        if time_match:
            race_data['ç™ºèµ°æ™‚åˆ»'] = f"{time_match.group(1)}:{time_match.group(2)}"
        
        # é‡é‡æ¡ä»¶
        if 'åˆ¥å®š' in race_text:
            race_data['é‡é‡æ¡ä»¶'] = 'åˆ¥å®š'
        elif 'å®šé‡' in race_text:
            race_data['é‡é‡æ¡ä»¶'] = 'å®šé‡'
        elif 'ãƒãƒ³ãƒ‡' in race_text or 'ãƒãƒ³ãƒ‡ã‚£' in race_text:
            race_data['é‡é‡æ¡ä»¶'] = 'ãƒãƒ³ãƒ‡'
        else:
            race_data['é‡é‡æ¡ä»¶'] = 'ä¸æ˜'
    
    # ç«¶é¦¬å ´
    venue_code = race_id[4:6]
    venue_map = {
        '30': 'é–€åˆ¥', '35': 'ç››å²¡', '36': 'æ°´æ²¢', '42': 'æµ¦å’Œ', '43': 'èˆ¹æ©‹',
        '44': 'å¤§äº•', '45': 'å·å´', '46': 'é‡‘æ²¢', '47': 'ç¬ æ¾', '48': 'åå¤å±‹',
        '50': 'åœ’ç”°', '51': 'å§«è·¯', '54': 'é«˜çŸ¥', '55': 'ä½è³€', '65': 'å¸¯åºƒã°'
    }
    race_data['ç«¶é¦¬å ´'] = venue_map.get(venue_code, 'ä¸æ˜')
    race_data['ãƒ¬ãƒ¼ã‚¹ç•ªå·'] = int(race_id[-2:])
    
    return race_data


def extract_horses(soup):
    """
    å‡ºé¦¬è¡¨ã‹ã‚‰é¦¬ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºï¼ˆãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ä»˜ãï¼‰
    """
    horses = []
    
    # å‡ºé¦¬è¡¨ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’å–å¾—
    horse_table = soup.find('table', class_='Shutuba_Table')
    if not horse_table:
        print(f"ğŸ” [DEBUG] Shutuba_Table not found, trying alternative selectors...")
        
        # ä»£æ›¿ã‚»ãƒ¬ã‚¯ã‚¿ã‚’è©¦ã™
        horse_table = soup.find('table', class_='HorseList')
        if horse_table:
            print(f"ğŸ” [DEBUG] Found table with class 'HorseList'")
        else:
            # ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’IDã§æ¤œç´¢
            horse_table = soup.find('table', id='shutuba_table')
            if horse_table:
                print(f"ğŸ” [DEBUG] Found table with id 'shutuba_table'")
    
    if not horse_table:
        return horses
    
    rows = horse_table.find_all('tr')
    print(f"ğŸ” [DEBUG] Total rows: {len(rows)}")
    
    for idx, row in enumerate(rows):
        # ãƒ‡ãƒ¼ã‚¿è¡Œã®ã¿å‡¦ç†
        if not row.find('td', class_='Waku'):
            continue
        
        horse_data = {}
        
        # æ ç•ª
        waku_td = row.find('td', class_='Waku')
        if waku_td:
            waku_text = waku_td.get_text(strip=True)
            try:
                horse_data['æ ç•ª'] = int(waku_text)
            except:
                horse_data['æ ç•ª'] = None
        
        # é¦¬ç•ª
        umaban_td = row.find('td', class_='Umaban')
        if umaban_td:
            umaban_text = umaban_td.get_text(strip=True)
            try:
                horse_data['é¦¬ç•ª'] = int(umaban_text)
            except:
                horse_data['é¦¬ç•ª'] = None
        
        # é¦¬åã¨horse_id
        horse_name_td = row.find('td', class_='Horse_Name')
        if horse_name_td:
            horse_link = horse_name_td.find('a')
            if horse_link:
                horse_data['é¦¬å'] = horse_link.get_text(strip=True)
                href = horse_link.get('href', '')
                horse_id_match = re.search(r'/horse/(\d+)', href)
                if horse_id_match:
                    horse_data['horse_id'] = horse_id_match.group(1)
        
        # æ€§é½¢
        sex_age_td = row.find('td', class_='Barei')
        if sex_age_td:
            horse_data['æ€§é½¢'] = sex_age_td.get_text(strip=True)
        
        # æ–¤é‡
        weight_td = row.find('td', class_='Weight')
        if weight_td:
            weight_text = weight_td.get_text(strip=True)
            try:
                horse_data['æ–¤é‡'] = float(weight_text)
            except:
                horse_data['æ–¤é‡'] = None
        
        # é¨æ‰‹
        jockey_td = row.find('td', class_='Jockey')
        if jockey_td:
            jockey_link = jockey_td.find('a')
            if jockey_link:
                horse_data['é¨æ‰‹'] = jockey_link.get_text(strip=True)
        
        # å©èˆ
        trainer_td = row.find('td', class_='Trainer')
        if trainer_td:
            trainer_link = trainer_td.find('a')
            if trainer_link:
                horse_data['å©èˆ'] = trainer_link.get_text(strip=True)
        
        # ã‚ªãƒƒã‚º
        odds_td = row.find('td', class_='Odds')
        if odds_td:
            odds_text = odds_td.get_text(strip=True)
            try:
                horse_data['ã‚ªãƒƒã‚º'] = float(odds_text)
            except:
                horse_data['ã‚ªãƒƒã‚º'] = None
        
        # äººæ°—
        popular_td = row.find('td', class_='Popular')
        if popular_td:
            popular_text = popular_td.get_text(strip=True)
            try:
                horse_data['äººæ°—'] = int(popular_text)
            except:
                horse_data['äººæ°—'] = None
        
        # é¦¬ä¸»
        owner_td = row.find('td', class_='Owner')
        if owner_td:
            horse_data['é¦¬ä¸»'] = owner_td.get_text(strip=True)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯
        if horse_data.get('é¦¬ç•ª') and horse_data.get('é¦¬å'):
            horses.append(horse_data)
            if idx == 1:  # æœ€åˆã®ãƒ‡ãƒ¼ã‚¿è¡Œã‚’ãƒ­ã‚°å‡ºåŠ›
                print(f"ğŸ” [DEBUG] First horse data: {horse_data}")
    
    print(f"ğŸ” [DEBUG] Total horses extracted: {len(horses)}")
    return horses


def main():
    """
    ãƒ¡ã‚¤ãƒ³å‡¦ç†ï¼ˆãƒ‡ãƒãƒƒã‚°ç‰ˆï¼‰
    """
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°
    ymd = None
    
    if len(sys.argv) > 1:
        ymd = sys.argv[1]
        print(f"ğŸ“… æŒ‡å®šã•ã‚ŒãŸæ—¥ä»˜: {ymd}")
    
    # today_jobs.latest.json ã‹ã‚‰å–å¾—
    try:
        with open('today_jobs.latest.json', 'r', encoding='utf-8') as f:
            jobs_data = json.load(f)
        
        race_ids = jobs_data.get('race_ids', [])
        
        if not ymd:
            ymd = jobs_data.get('date') or jobs_data.get('ymd', '')
            if ymd:
                print(f"ğŸ“… å–å¾—ã—ãŸæ—¥ä»˜: {ymd}")
            else:
                print("âš ï¸ æ—¥ä»˜ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
        
        if not race_ids:
            print("âŒ race_idsãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            sys.exit(1)
        
        print(f"ğŸ“Š å¯¾è±¡ãƒ¬ãƒ¼ã‚¹æ•°: {len(race_ids)}")
        print("-" * 50)
        
        # ğŸ”¥ ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰: æœ€åˆã®1ãƒ¬ãƒ¼ã‚¹ã®ã¿ãƒ†ã‚¹ãƒˆ
        print(f"\nğŸ”¥ ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰: æœ€åˆã®1ãƒ¬ãƒ¼ã‚¹ã®ã¿ãƒ†ã‚¹ãƒˆ\n")
        race_ids = race_ids[:1]
        
    except FileNotFoundError:
        print("âŒ today_jobs.latest.json ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        sys.exit(1)
    except json.JSONDecodeError:
        print("âŒ today_jobs.latest.json ã®å½¢å¼ãŒä¸æ­£ã§ã™")
        sys.exit(1)
    
    # ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿å–å¾—
    all_races = []
    success_count = 0
    
    for i, race_id in enumerate(race_ids, 1):
        print(f"\n[{i}/{len(race_ids)}] {race_id} ã‚’å–å¾—ä¸­...")
        
        race_data = fetch_race_data(race_id)
        
        if race_data:
            all_races.append(race_data)
            success_count += 1
        
        time.sleep(1)
    
    # çµæœä¿å­˜
    output_file = f"race_data_{ymd}_debug.json"
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump({
            'ymd': ymd,
            'å–å¾—æ—¥æ™‚': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'ãƒ¬ãƒ¼ã‚¹æ•°': len(all_races),
            'races': all_races
        }, f, ensure_ascii=False, indent=2)
    
    print("\n" + "=" * 50)
    print(f"âœ… å®Œäº†: {success_count}/{len(race_ids)} ãƒ¬ãƒ¼ã‚¹")
    print(f"ğŸ’¾ ä¿å­˜å…ˆ: {output_file}")
    
    if all_races:
        total_horses = sum(race.get('å–å¾—é ­æ•°', 0) for race in all_races)
        print(f"ğŸ´ ç·é¦¬æ•°: {total_horses}é ­")


if __name__ == '__main__':
    main()
