#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å‡ºé¦¬è¡¨ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆä¿®æ­£ç‰ˆ v3.0ï¼‰
- é¦¬ãƒªãƒ³ã‚¯ãƒ™ãƒ¼ã‚¹ã®æŠ½å‡ºæ–¹å¼ã«å¤‰æ›´
- ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ ã«ä¾å­˜ã—ãªã„
"""

import json
import re
import time
import sys
from datetime import datetime
import requests
from bs4 import BeautifulSoup

def fetch_race_data(race_id):
    """
    æŒ‡å®šã•ã‚ŒãŸrace_idã®å‡ºé¦¬è¡¨ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆé¦¬ãƒªãƒ³ã‚¯ãƒ™ãƒ¼ã‚¹ï¼‰
    """
    url = f"https://nar.netkeiba.com/race/shutuba.html?race_id={race_id}"
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    }
    
    try:
        resp = requests.get(url, headers=headers, timeout=10)
        resp.encoding = 'EUC-JP'
        
        if resp.status_code != 200:
            print(f"âŒ HTTP Error {resp.status_code} for race_id={race_id}")
            return None
        
        soup = BeautifulSoup(resp.text, 'html.parser')
        
        # ãƒ¬ãƒ¼ã‚¹åŸºæœ¬æƒ…å ±ã®å–å¾—
        race_info = extract_race_info(soup, race_id)
        if not race_info:
            print(f"âš ï¸ ãƒ¬ãƒ¼ã‚¹æƒ…å ±ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ: {race_id}")
            return None
        
        # é¦¬ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ï¼ˆæ–°æ–¹å¼ï¼‰
        horses = extract_horses_from_links(soup)
        if not horses:
            print(f"âš ï¸ é¦¬ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ: {race_id}")
            return None
        
        race_info['horses'] = horses
        race_info['å–å¾—é ­æ•°'] = len(horses)
        
        print(f"âœ… {race_info.get('ãƒ¬ãƒ¼ã‚¹å', 'N/A')}: {len(horses)}é ­")
        
        return race_info
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {race_id} - {str(e)}")
        return None


def extract_race_info(soup, race_id):
    """
    ãƒ¬ãƒ¼ã‚¹åŸºæœ¬æƒ…å ±ã‚’æŠ½å‡º
    """
    race_data = {
        'race_id': race_id
    }
    
    # ãƒ¬ãƒ¼ã‚¹å
    race_title = soup.find('div', class_='RaceName')
    if race_title:
        race_data['ãƒ¬ãƒ¼ã‚¹å'] = race_title.get_text(strip=True)
    
    # ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ï¼ˆè·é›¢ã€ç™ºèµ°æ™‚åˆ»ãªã©ï¼‰
    race_data_div = soup.find('div', class_='RaceData01')
    if race_data_div:
        race_text = race_data_div.get_text(strip=True)
        
        # è·é›¢ã®æŠ½å‡º
        distance_match = re.search(r'([ãƒ€èŠ])(\d+)m', race_text)
        if distance_match:
            race_data['ãƒˆãƒ©ãƒƒã‚¯'] = distance_match.group(1)
            race_data['è·é›¢'] = int(distance_match.group(2))
        
        # ç™ºèµ°æ™‚åˆ»
        time_match = re.search(r'(\d{1,2}):(\d{2})ç™ºèµ°', race_text)
        if time_match:
            race_data['ç™ºèµ°æ™‚åˆ»'] = f"{time_match.group(1)}:{time_match.group(2)}"
        
        # é‡é‡æ¡ä»¶
        if 'åˆ¥å®š' in race_text:
            race_data['é‡é‡æ¡ä»¶'] = 'åˆ¥å®š'
        elif 'å®šé‡' in race_text:
            race_data['é‡é‡æ¡ä»¶'] = 'å®šé‡'
        elif 'ãƒãƒ³ãƒ‡' in race_text or 'ãƒãƒ³ãƒ‡ã‚£' in race_text:
            race_data['é‡é‡æ¡ä»¶'] = 'ãƒãƒ³ãƒ‡'
        else:
            race_data['é‡é‡æ¡ä»¶'] = 'ä¸æ˜'
    
    # ç«¶é¦¬å ´
    venue_code = race_id[4:6]
    venue_map = {
        '30': 'é–€åˆ¥', '35': 'ç››å²¡', '36': 'æ°´æ²¢', '42': 'æµ¦å’Œ', '43': 'èˆ¹æ©‹',
        '44': 'å¤§äº•', '45': 'å·å´', '46': 'é‡‘æ²¢', '47': 'ç¬ æ¾', '48': 'åå¤å±‹',
        '50': 'åœ’ç”°', '51': 'å§«è·¯', '54': 'é«˜çŸ¥', '55': 'ä½è³€', '65': 'å¸¯åºƒã°'
    }
    race_data['ç«¶é¦¬å ´'] = venue_map.get(venue_code, 'ä¸æ˜')
    race_data['ãƒ¬ãƒ¼ã‚¹ç•ªå·'] = int(race_id[-2:])
    
    return race_data


def extract_horses_from_links(soup):
    """
    é¦¬ãƒªãƒ³ã‚¯ã‹ã‚‰ç›´æ¥é¦¬ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºï¼ˆæ–°æ–¹å¼ï¼‰
    """
    horses = []
    
    # å‡ºé¦¬è¡¨ã‚¨ãƒªã‚¢ã‚’ç‰¹å®š
    # ä¸€èˆ¬çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³: ShutubaTable, HorseList, Race_HorseList ãªã©
    shutuba_area = (
        soup.find('table', class_='Shutuba_Table') or
        soup.find('table', class_='HorseList') or
        soup.find('div', class_='Race_HorseList') or
        soup.find('div', id='All_HorseList')
    )
    
    if not shutuba_area:
        print(f"âš ï¸ å‡ºé¦¬è¡¨ã‚¨ãƒªã‚¢ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return horses
    
    # ã™ã¹ã¦ã®è¡Œï¼ˆtrï¼‰ã‚’å–å¾—
    rows = shutuba_area.find_all('tr')
    
    for row in rows:
        # é¦¬åãƒªãƒ³ã‚¯ã‚’æ¢ã™
        horse_link = row.find('a', href=re.compile(r'/horse/\d+'))
        if not horse_link:
            continue
        
        horse_data = {}
        
        # é¦¬åã¨horse_id
        horse_data['é¦¬å'] = horse_link.get_text(strip=True)
        href = horse_link.get('href', '')
        horse_id_match = re.search(r'/horse/(\d+)', href)
        if horse_id_match:
            horse_data['horse_id'] = horse_id_match.group(1)
        
        # ã™ã¹ã¦ã®tdã‚»ãƒ«ã‚’å–å¾—
        cells = row.find_all('td')
        
        # ã‚»ãƒ«ã‹ã‚‰æƒ…å ±ã‚’æŠ½å‡ºï¼ˆæŸ”è»Ÿãªæ–¹æ³•ï¼‰
        for cell in cells:
            cell_text = cell.get_text(strip=True)
            cell_class = ' '.join(cell.get('class', []))
            
            # æ ç•ªï¼ˆæ•°å­—1æ¡ + è‰²ã‚¯ãƒ©ã‚¹ï¼‰
            if 'Waku' in cell_class and cell_text.isdigit():
                horse_data['æ ç•ª'] = int(cell_text)
            
            # é¦¬ç•ªï¼ˆæ•°å­—1-2æ¡ + Umaban ã‚¯ãƒ©ã‚¹ï¼‰
            elif 'Umaban' in cell_class and cell_text.isdigit():
                horse_data['é¦¬ç•ª'] = int(cell_text)
            
            # æ€§é½¢ï¼ˆä¾‹: ç‰¡4, ç‰3ï¼‰
            elif re.match(r'^[ç‰¡ç‰ã‚»][0-9]$', cell_text):
                horse_data['æ€§é½¢'] = cell_text
            
            # æ–¤é‡ï¼ˆä¾‹: 54.0, 55.5ï¼‰
            elif re.match(r'^\d{2}\.\d$', cell_text):
                try:
                    horse_data['æ–¤é‡'] = float(cell_text)
                except:
                    pass
            
            # ã‚ªãƒƒã‚ºï¼ˆä¾‹: 3.5, 12.8ï¼‰
            elif 'Odds' in cell_class:
                try:
                    horse_data['ã‚ªãƒƒã‚º'] = float(cell_text)
                except:
                    pass
            
            # äººæ°—ï¼ˆä¾‹: 1, 2, 3ï¼‰
            elif 'Popular' in cell_class and cell_text.isdigit():
                horse_data['äººæ°—'] = int(cell_text)
        
        # é¨æ‰‹ãƒªãƒ³ã‚¯ã‚’æ¢ã™
        jockey_link = row.find('a', href=re.compile(r'/jockey/'))
        if jockey_link:
            horse_data['é¨æ‰‹'] = jockey_link.get_text(strip=True)
        
        # èª¿æ•™å¸«ãƒªãƒ³ã‚¯ã‚’æ¢ã™
        trainer_link = row.find('a', href=re.compile(r'/trainer/'))
        if trainer_link:
            horse_data['å©èˆ'] = trainer_link.get_text(strip=True)
        
        # é¦¬ä¸»ï¼ˆOwner ã‚¯ãƒ©ã‚¹ï¼‰
        owner_cell = row.find('td', class_='Owner')
        if owner_cell:
            horse_data['é¦¬ä¸»'] = owner_cell.get_text(strip=True)
        
        # æœ€ä½é™ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°è¿½åŠ 
        if horse_data.get('é¦¬å') and horse_data.get('horse_id'):
            horses.append(horse_data)
    
    return horses


def main():
    """
    ãƒ¡ã‚¤ãƒ³å‡¦ç†
    """
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‹ã‚‰ ymd ã‚’å–å¾—
    ymd = None
    
    if len(sys.argv) > 1:
        ymd = sys.argv[1]
        print(f"ğŸ“… æŒ‡å®šã•ã‚ŒãŸæ—¥ä»˜: {ymd}")
    
    # today_jobs.latest.json ã‹ã‚‰ race_id ãƒªã‚¹ãƒˆã‚’èª­ã¿è¾¼ã¿
    try:
        with open('today_jobs.latest.json', 'r', encoding='utf-8') as f:
            jobs_data = json.load(f)
        
        race_ids = jobs_data.get('race_ids', [])
        
        # ymd ãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯ jobs_data ã‹ã‚‰å–å¾—
        if not ymd:
            ymd = jobs_data.get('date') or jobs_data.get('ymd', '')
            if ymd:
                print(f"ğŸ“… å–å¾—ã—ãŸæ—¥ä»˜: {ymd}")
            else:
                print("âš ï¸ æ—¥ä»˜ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸï¼ˆç©ºæ–‡å­—åˆ—ã§ç¶šè¡Œï¼‰")
        
        if not race_ids:
            print("âŒ race_idsãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            sys.exit(1)
        
        print(f"ğŸ“Š å¯¾è±¡ãƒ¬ãƒ¼ã‚¹æ•°: {len(race_ids)}")
        print("-" * 50)
        
    except FileNotFoundError:
        print("âŒ today_jobs.latest.json ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        sys.exit(1)
    except json.JSONDecodeError:
        print("âŒ today_jobs.latest.json ã®å½¢å¼ãŒä¸æ­£ã§ã™")
        sys.exit(1)
    
    # å„ãƒ¬ãƒ¼ã‚¹ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    all_races = []
    success_count = 0
    
    for i, race_id in enumerate(race_ids, 1):
        print(f"[{i}/{len(race_ids)}] {race_id} ã‚’å–å¾—ä¸­...")
        
        race_data = fetch_race_data(race_id)
        
        if race_data:
            all_races.append(race_data)
            success_count += 1
        
        # ã‚µãƒ¼ãƒãƒ¼è² è·è»½æ¸›ã®ãŸã‚å¾…æ©Ÿ
        if i < len(race_ids):
            time.sleep(1)
    
    # çµæœã‚’ä¿å­˜
    output_file = f"race_data_{ymd}.json"
    
    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
    import os
    if os.path.exists(output_file):
        backup_file = f"race_data_{ymd}.backup.json"
        os.rename(output_file, backup_file)
        print(f"ğŸ“¦ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ: {backup_file}")
    
    # æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump({
            'ymd': ymd,
            'å–å¾—æ—¥æ™‚': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'ãƒ¬ãƒ¼ã‚¹æ•°': len(all_races),
            'races': all_races
        }, f, ensure_ascii=False, indent=2)
    
    print("-" * 50)
    print(f"âœ… å®Œäº†: {success_count}/{len(race_ids)} ãƒ¬ãƒ¼ã‚¹")
    print(f"ğŸ’¾ ä¿å­˜å…ˆ: {output_file}")
    
    # çµ±è¨ˆæƒ…å ±
    total_horses = sum(race.get('å–å¾—é ­æ•°', 0) for race in all_races)
    print(f"ğŸ´ ç·é¦¬æ•°: {total_horses}é ­")


if __name__ == '__main__':
    main()
