#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å‡ºé¦¬è¡¨ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆãƒ‡ãƒãƒƒã‚°ç‰ˆ v3.1ï¼‰
- 1é ­ã—ã‹å–å¾—ã§ããªã„å•é¡Œã‚’èª¿æŸ»
- è©³ç´°ãƒ­ã‚°ã‚’è¿½åŠ 
"""

import json
import re
import time
import sys
from datetime import datetime
import requests
from bs4 import BeautifulSoup

def fetch_race_data(race_id):
    """
    æŒ‡å®šã•ã‚ŒãŸrace_idã®å‡ºé¦¬è¡¨ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆè©³ç´°ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ä»˜ãï¼‰
    """
    url = f"https://nar.netkeiba.com/race/shutuba.html?race_id={race_id}"
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    }
    
    try:
        resp = requests.get(url, headers=headers, timeout=10)
        resp.encoding = 'EUC-JP'
        
        if resp.status_code != 200:
            print(f"âŒ HTTP Error {resp.status_code} for race_id={race_id}")
            return None
        
        soup = BeautifulSoup(resp.text, 'html.parser')
        
        # ãƒ¬ãƒ¼ã‚¹åŸºæœ¬æƒ…å ±ã®å–å¾—
        race_info = extract_race_info(soup, race_id)
        if not race_info:
            print(f"âš ï¸ ãƒ¬ãƒ¼ã‚¹æƒ…å ±ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ: {race_id}")
            return None
        
        # é¦¬ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ï¼ˆãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ä»˜ãï¼‰
        horses = extract_horses_from_links_debug(soup, race_id)
        if not horses:
            print(f"âš ï¸ é¦¬ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ: {race_id}")
            return None
        
        race_info['horses'] = horses
        race_info['å–å¾—é ­æ•°'] = len(horses)
        
        print(f"âœ… {race_info.get('ãƒ¬ãƒ¼ã‚¹å', 'N/A')}: {len(horses)}é ­")
        
        return race_info
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {race_id} - {str(e)}")
        import traceback
        traceback.print_exc()
        return None


def extract_race_info(soup, race_id):
    """
    ãƒ¬ãƒ¼ã‚¹åŸºæœ¬æƒ…å ±ã‚’æŠ½å‡º
    """
    race_data = {
        'race_id': race_id
    }
    
    # ãƒ¬ãƒ¼ã‚¹å
    race_title = soup.find('div', class_='RaceName')
    if race_title:
        race_data['ãƒ¬ãƒ¼ã‚¹å'] = race_title.get_text(strip=True)
    
    # ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿
    race_data_div = soup.find('div', class_='RaceData01')
    if race_data_div:
        race_text = race_data_div.get_text(strip=True)
        
        # è·é›¢
        distance_match = re.search(r'([ãƒ€èŠ])(\d+)m', race_text)
        if distance_match:
            race_data['ãƒˆãƒ©ãƒƒã‚¯'] = distance_match.group(1)
            race_data['è·é›¢'] = int(distance_match.group(2))
        
        # ç™ºèµ°æ™‚åˆ»
        time_match = re.search(r'(\d{1,2}):(\d{2})ç™ºèµ°', race_text)
        if time_match:
            race_data['ç™ºèµ°æ™‚åˆ»'] = f"{time_match.group(1)}:{time_match.group(2)}"
        
        # é‡é‡æ¡ä»¶
        if 'åˆ¥å®š' in race_text:
            race_data['é‡é‡æ¡ä»¶'] = 'åˆ¥å®š'
        elif 'å®šé‡' in race_text:
            race_data['é‡é‡æ¡ä»¶'] = 'å®šé‡'
        elif 'ãƒãƒ³ãƒ‡' in race_text or 'ãƒãƒ³ãƒ‡ã‚£' in race_text:
            race_data['é‡é‡æ¡ä»¶'] = 'ãƒãƒ³ãƒ‡'
        else:
            race_data['é‡é‡æ¡ä»¶'] = 'ä¸æ˜'
    
    # ç«¶é¦¬å ´
    venue_code = race_id[4:6]
    venue_map = {
        '30': 'é–€åˆ¥', '35': 'ç››å²¡', '36': 'æ°´æ²¢', '42': 'æµ¦å’Œ', '43': 'èˆ¹æ©‹',
        '44': 'å¤§äº•', '45': 'å·å´', '46': 'é‡‘æ²¢', '47': 'ç¬ æ¾', '48': 'åå¤å±‹',
        '50': 'åœ’ç”°', '51': 'å§«è·¯', '54': 'é«˜çŸ¥', '55': 'ä½è³€', '65': 'å¸¯åºƒã°'
    }
    race_data['ç«¶é¦¬å ´'] = venue_map.get(venue_code, 'ä¸æ˜')
    race_data['ãƒ¬ãƒ¼ã‚¹ç•ªå·'] = int(race_id[-2:])
    
    return race_data


def extract_horses_from_links_debug(soup, race_id):
    """
    é¦¬ãƒªãƒ³ã‚¯ã‹ã‚‰ç›´æ¥é¦¬ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºï¼ˆè©³ç´°ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ä»˜ãï¼‰
    """
    horses = []
    
    print(f"\nğŸ” [DEBUG] ========== {race_id} ==========")
    
    # å‡ºé¦¬è¡¨ã‚¨ãƒªã‚¢ã‚’ç‰¹å®š
    shutuba_area = (
        soup.find('table', class_='Shutuba_Table') or
        soup.find('table', class_='HorseList') or
        soup.find('div', class_='Race_HorseList') or
        soup.find('div', id='All_HorseList')
    )
    
    if not shutuba_area:
        print(f"ğŸ” [DEBUG] å‡ºé¦¬è¡¨ã‚¨ãƒªã‚¢ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        # ä»£æ›¿æ¤œç´¢: ã™ã¹ã¦ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ç¢ºèª
        all_tables = soup.find_all('table')
        print(f"ğŸ” [DEBUG] ãƒšãƒ¼ã‚¸å†…ã®å…¨ãƒ†ãƒ¼ãƒ–ãƒ«æ•°: {len(all_tables)}")
        for idx, table in enumerate(all_tables[:5]):
            classes = table.get('class', [])
            print(f"ğŸ” [DEBUG] Table {idx+1} classes: {classes}")
        
        return horses
    
    # ã‚¨ãƒªã‚¢ã®ã‚¯ãƒ©ã‚¹åã‚’ç¢ºèª
    area_class = shutuba_area.get('class', [])
    area_name = shutuba_area.name
    print(f"ğŸ” [DEBUG] å‡ºé¦¬è¡¨ã‚¨ãƒªã‚¢: <{area_name} class='{area_class}'>")
    
    # ã™ã¹ã¦ã®è¡Œï¼ˆtrï¼‰ã‚’å–å¾—
    rows = shutuba_area.find_all('tr')
    print(f"ğŸ” [DEBUG] ç·è¡Œæ•°: {len(rows)}")
    
    # æœ€åˆã®3è¡Œã‚’è©³ç´°è¡¨ç¤º
    for idx, row in enumerate(rows[:3]):
        cells = row.find_all(['td', 'th'])
        cell_texts = [cell.get_text(strip=True)[:20] for cell in cells[:5]]
        print(f"ğŸ” [DEBUG] Row {idx+1}: {len(cells)} cells - {cell_texts}")
    
    # é¦¬ãƒªãƒ³ã‚¯ã‚’å«ã‚€è¡Œã‚’æŠ½å‡º
    horse_rows = []
    for row in rows:
        horse_link = row.find('a', href=re.compile(r'/horse/\d+'))
        if horse_link:
            horse_rows.append(row)
    
    print(f"ğŸ” [DEBUG] é¦¬ãƒªãƒ³ã‚¯ã‚’å«ã‚€è¡Œæ•°: {len(horse_rows)}")
    
    # å„é¦¬è¡Œã‚’å‡¦ç†
    for idx, row in enumerate(horse_rows, 1):
        horse_data = {}
        
        # é¦¬åã¨horse_id
        horse_link = row.find('a', href=re.compile(r'/horse/\d+'))
        if horse_link:
            horse_data['é¦¬å'] = horse_link.get_text(strip=True)
            href = horse_link.get('href', '')
            horse_id_match = re.search(r'/horse/(\d+)', href)
            if horse_id_match:
                horse_data['horse_id'] = horse_id_match.group(1)
        
        # ã™ã¹ã¦ã®tdã‚»ãƒ«ã‚’å–å¾—
        cells = row.find_all('td')
        
        if idx == 1:  # æœ€åˆã®é¦¬ã®è©³ç´°ãƒ­ã‚°
            print(f"ğŸ” [DEBUG] é¦¬1ã®ã‚»ãƒ«æ•°: {len(cells)}")
            for cell_idx, cell in enumerate(cells[:10]):
                cell_class = cell.get('class', [])
                cell_text = cell.get_text(strip=True)
                print(f"ğŸ” [DEBUG] Cell {cell_idx+1}: class={cell_class}, text='{cell_text[:30]}'")
        
        # ã‚»ãƒ«ã‹ã‚‰æƒ…å ±ã‚’æŠ½å‡º
        for cell in cells:
            cell_text = cell.get_text(strip=True)
            cell_class = ' '.join(cell.get('class', []))
            
            # æ ç•ª
            if 'Waku' in cell_class and cell_text.isdigit():
                horse_data['æ ç•ª'] = int(cell_text)
            
            # é¦¬ç•ª
            elif 'Umaban' in cell_class and cell_text.isdigit():
                horse_data['é¦¬ç•ª'] = int(cell_text)
            
            # æ€§é½¢
            elif re.match(r'^[ç‰¡ç‰ã‚»][0-9]$', cell_text):
                horse_data['æ€§é½¢'] = cell_text
            
            # æ–¤é‡
            elif re.match(r'^\d{2}\.\d$', cell_text):
                try:
                    horse_data['æ–¤é‡'] = float(cell_text)
                except:
                    pass
            
            # ã‚ªãƒƒã‚º
            elif 'Odds' in cell_class:
                try:
                    horse_data['ã‚ªãƒƒã‚º'] = float(cell_text)
                except:
                    pass
            
            # äººæ°—
            elif 'Popular' in cell_class and cell_text.isdigit():
                horse_data['äººæ°—'] = int(cell_text)
        
        # é¨æ‰‹ãƒªãƒ³ã‚¯
        jockey_link = row.find('a', href=re.compile(r'/jockey/'))
        if jockey_link:
            horse_data['é¨æ‰‹'] = jockey_link.get_text(strip=True)
        
        # èª¿æ•™å¸«ãƒªãƒ³ã‚¯
        trainer_link = row.find('a', href=re.compile(r'/trainer/'))
        if trainer_link:
            horse_data['å©èˆ'] = trainer_link.get_text(strip=True)
        
        # é¦¬ä¸»
        owner_cell = row.find('td', class_='Owner')
        if owner_cell:
            horse_data['é¦¬ä¸»'] = owner_cell.get_text(strip=True)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯
        if horse_data.get('é¦¬å') and horse_data.get('horse_id'):
            horses.append(horse_data)
            if idx == 1:
                print(f"ğŸ” [DEBUG] é¦¬1ã®ãƒ‡ãƒ¼ã‚¿: {horse_data}")
        else:
            print(f"ğŸ” [DEBUG] é¦¬{idx}ã®ãƒ‡ãƒ¼ã‚¿ä¸è¶³ï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰: é¦¬å={horse_data.get('é¦¬å')}, horse_id={horse_data.get('horse_id')}")
    
    print(f"ğŸ” [DEBUG] æŠ½å‡ºã•ã‚ŒãŸé¦¬æ•°: {len(horses)}")
    print(f"ğŸ” [DEBUG] ==========================================\n")
    
    return horses


def main():
    """
    ãƒ¡ã‚¤ãƒ³å‡¦ç†ï¼ˆãƒ‡ãƒãƒƒã‚°ç‰ˆ - æœ€åˆã®1ãƒ¬ãƒ¼ã‚¹ã®ã¿ï¼‰
    """
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°
    ymd = None
    
    if len(sys.argv) > 1:
        ymd = sys.argv[1]
        print(f"ğŸ“… æŒ‡å®šã•ã‚ŒãŸæ—¥ä»˜: {ymd}")
    
    # today_jobs.latest.json ã‹ã‚‰å–å¾—
    try:
        with open('today_jobs.latest.json', 'r', encoding='utf-8') as f:
            jobs_data = json.load(f)
        
        race_ids = jobs_data.get('race_ids', [])
        
        if not ymd:
            ymd = jobs_data.get('date') or jobs_data.get('ymd', '')
            if ymd:
                print(f"ğŸ“… å–å¾—ã—ãŸæ—¥ä»˜: {ymd}")
            else:
                print("âš ï¸ æ—¥ä»˜ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
        
        if not race_ids:
            print("âŒ race_idsãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            sys.exit(1)
        
        print(f"ğŸ“Š å¯¾è±¡ãƒ¬ãƒ¼ã‚¹æ•°: {len(race_ids)}")
        print("-" * 50)
        
        # ğŸ”¥ ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰: æœ€åˆã®1ãƒ¬ãƒ¼ã‚¹ã®ã¿ãƒ†ã‚¹ãƒˆ
        print(f"\nğŸ”¥ ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰: æœ€åˆã®1ãƒ¬ãƒ¼ã‚¹ã®ã¿ãƒ†ã‚¹ãƒˆ\n")
        race_ids = race_ids[:1]
        
    except FileNotFoundError:
        print("âŒ today_jobs.latest.json ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        sys.exit(1)
    except json.JSONDecodeError:
        print("âŒ today_jobs.latest.json ã®å½¢å¼ãŒä¸æ­£ã§ã™")
        sys.exit(1)
    
    # ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿å–å¾—
    all_races = []
    success_count = 0
    
    for i, race_id in enumerate(race_ids, 1):
        print(f"\n[{i}/{len(race_ids)}] {race_id} ã‚’å–å¾—ä¸­...")
        
        race_data = fetch_race_data(race_id)
        
        if race_data:
            all_races.append(race_data)
            success_count += 1
    
    # çµæœä¿å­˜
    output_file = f"race_data_{ymd}_debug.json"
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump({
            'ymd': ymd,
            'å–å¾—æ—¥æ™‚': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'ãƒ¬ãƒ¼ã‚¹æ•°': len(all_races),
            'races': all_races
        }, f, ensure_ascii=False, indent=2)
    
    print("\n" + "=" * 50)
    print(f"âœ… å®Œäº†: {success_count}/{len(race_ids)} ãƒ¬ãƒ¼ã‚¹")
    print(f"ğŸ’¾ ä¿å­˜å…ˆ: {output_file}")
    
    if all_races:
        total_horses = sum(race.get('å–å¾—é ­æ•°', 0) for race in all_races)
        print(f"ğŸ´ ç·é¦¬æ•°: {total_horses}é ­")


if __name__ == '__main__':
    main()
